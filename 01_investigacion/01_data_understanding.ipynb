{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33603ced2755bea0",
   "metadata": {},
   "source": [
    "# 01 - Data Understanding\n",
    "\n",
    "## Objetivo del Notebook\n",
    "Este notebook realiza una **revisi√≥n inicial (Data Understanding)** del dataset disponible para el proyecto de predicci√≥n de calor√≠as quemadas durante el ejercicio f√≠sico.\n",
    "\n",
    "**Objetivos espec√≠ficos**:\n",
    "1. Confirmar el esquema y estructura de los datos\n",
    "2. Identificar tipos de datos de cada variable\n",
    "3. Detectar valores faltantes (missing values)\n",
    "4. Calcular estad√≠sticas descriptivas completas\n",
    "5. Analizar distribuciones y caracter√≠sticas de las variables\n",
    "6. Detectar valores at√≠picos (outliers)\n",
    "7. Evaluar la calidad general del dataset\n",
    "\n",
    "**Contexto del proyecto**: Desarrollo de un modelo de Machine Learning para predecir el gasto energ√©tico (calor√≠as) durante actividad f√≠sica basado en variables biom√©tricas y fisiol√≥gicas medibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T22:12:34.799289Z",
     "start_time": "2025-09-30T22:12:34.420659Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_CSV: ..\\data\\raw\\train.csv\n",
      "TEST_CSV: ..\\data\\raw\\test.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "TRAIN_CSV = DATA_DIR / \"raw\" / \"train.csv\"\n",
    "TEST_CSV = DATA_DIR / \"raw\" / \"test.csv\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"TRAIN_CSV: {TRAIN_CSV}\")\n",
    "print(f\"TEST_CSV: {TEST_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92cefc5a6440c9bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T22:12:38.401443Z",
     "start_time": "2025-09-30T22:12:37.808906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (750000, 9)\n",
      "Test shape: (250000, 8)\n",
      "Train columns: ['id', 'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']\n",
      "Test columns: ['id', 'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>189.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>163.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>51</td>\n",
       "      <td>161.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>192.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>166.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Sex  Age  Height  Weight  Duration  Heart_Rate  Body_Temp  Calories\n",
       "0   0    male   36   189.0    82.0      26.0       101.0       41.0     150.0\n",
       "1   1  female   64   163.0    60.0       8.0        85.0       39.7      34.0\n",
       "2   2  female   51   161.0    64.0       7.0        84.0       39.8      29.0\n",
       "3   3    male   20   192.0    90.0      25.0       105.0       40.7     140.0\n",
       "4   4  female   38   166.0    61.0      25.0       102.0       40.6     146.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar archivos\n",
    "train_raw = pd.read_csv(TRAIN_CSV)\n",
    "test_raw = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(\"Train shape:\", train_raw.shape)\n",
    "print(\"Test shape:\", test_raw.shape)\n",
    "print(\"Train columns:\", train_raw.columns.tolist())\n",
    "print(\"Test columns:\", test_raw.columns.tolist())\n",
    "\n",
    "# Previsualizar\n",
    "display(train_raw.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3405081c4b1f8bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:37:00.032153Z",
     "start_time": "2025-09-14T14:36:59.789673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   id          750000 non-null  int64  \n",
      " 1   Sex         750000 non-null  object \n",
      " 2   Age         750000 non-null  int64  \n",
      " 3   Height      750000 non-null  float64\n",
      " 4   Weight      750000 non-null  float64\n",
      " 5   Duration    750000 non-null  float64\n",
      " 6   Heart_Rate  750000 non-null  float64\n",
      " 7   Body_Temp   750000 non-null  float64\n",
      " 8   Calories    750000 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 51.5+ MB\n",
      "None\n",
      "\n",
      "Nulos por columna (train):\n",
      " id            0\n",
      "Sex           0\n",
      "Age           0\n",
      "Height        0\n",
      "Weight        0\n",
      "Duration      0\n",
      "Heart_Rate    0\n",
      "Body_Temp     0\n",
      "Calories      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Informaci√≥n y nulos (solo train, porque tiene target)\n",
    "print(train_raw.info())\n",
    "print(\"\\nNulos por columna (train):\\n\", train_raw.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf409278118602a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:37:09.087513Z",
     "start_time": "2025-09-14T14:37:08.648814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374999.5</td>\n",
       "      <td>216506.495284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187499.75</td>\n",
       "      <td>374999.5</td>\n",
       "      <td>562499.25</td>\n",
       "      <td>749999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>750000</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>375721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.420404</td>\n",
       "      <td>15.175049</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.697685</td>\n",
       "      <td>12.824496</td>\n",
       "      <td>126.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.145668</td>\n",
       "      <td>13.982704</td>\n",
       "      <td>36.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.421015</td>\n",
       "      <td>8.354095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart_Rate</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.483995</td>\n",
       "      <td>9.449845</td>\n",
       "      <td>67.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Body_Temp</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.036253</td>\n",
       "      <td>0.779875</td>\n",
       "      <td>37.1</td>\n",
       "      <td>39.6</td>\n",
       "      <td>40.3</td>\n",
       "      <td>40.7</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calories</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.282781</td>\n",
       "      <td>62.395349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count unique     top    freq        mean            std    min  \\\n",
       "id          750000.0    NaN     NaN     NaN    374999.5  216506.495284    0.0   \n",
       "Sex           750000      2  female  375721         NaN            NaN    NaN   \n",
       "Age         750000.0    NaN     NaN     NaN   41.420404      15.175049   20.0   \n",
       "Height      750000.0    NaN     NaN     NaN  174.697685      12.824496  126.0   \n",
       "Weight      750000.0    NaN     NaN     NaN   75.145668      13.982704   36.0   \n",
       "Duration    750000.0    NaN     NaN     NaN   15.421015       8.354095    1.0   \n",
       "Heart_Rate  750000.0    NaN     NaN     NaN   95.483995       9.449845   67.0   \n",
       "Body_Temp   750000.0    NaN     NaN     NaN   40.036253       0.779875   37.1   \n",
       "Calories    750000.0    NaN     NaN     NaN   88.282781      62.395349    1.0   \n",
       "\n",
       "                  25%       50%        75%       max  \n",
       "id          187499.75  374999.5  562499.25  749999.0  \n",
       "Sex               NaN       NaN        NaN       NaN  \n",
       "Age              28.0      40.0       52.0      79.0  \n",
       "Height          164.0     174.0      185.0     222.0  \n",
       "Weight           63.0      74.0       87.0     132.0  \n",
       "Duration          8.0      15.0       23.0      30.0  \n",
       "Heart_Rate       88.0      95.0      103.0     128.0  \n",
       "Body_Temp        39.6      40.3       40.7      41.5  \n",
       "Calories         34.0      77.0      136.0     314.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estad√≠sticas descriptivas (train)\n",
    "display(train_raw.describe(include='all').T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ESTAD√çSTICAS DESCRIPTIVAS EXTENDIDAS\n",
    "# =============================================================================\n",
    "# Generar un an√°lisis estad√≠stico m√°s completo que el m√©todo .describe() b√°sico\n",
    "# Incluye m√©tricas adicionales relevantes para an√°lisis de datos cient√≠ficos y tesis\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ESTAD√çSTICAS DESCRIPTIVAS EXTENDIDAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Seleccionar solo columnas num√©ricas para an√°lisis cuantitativo\n",
    "# Se excluye 'id' ya que es solo un identificador sin valor estad√≠stico\n",
    "numeric_cols = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']\n",
    "\n",
    "# Funci√≥n para calcular estad√≠sticas completas de una serie\n",
    "def compute_extended_stats(series):\n",
    "    \"\"\"Calcula estad√≠sticas descriptivas extendidas para una serie num√©rica.\"\"\"\n",
    "    return pd.Series({\n",
    "        'Count': series.count(),              # N√∫mero de observaciones no nulas\n",
    "        'Mean': series.mean(),                # Media aritm√©tica\n",
    "        'Median': series.median(),            # Mediana (percentil 50, robusto a outliers)\n",
    "        'Std': series.std(),                  # Desviaci√≥n est√°ndar (dispersi√≥n)\n",
    "        'Min': series.min(),                  # Valor m√≠nimo observado\n",
    "        'Q1 (25%)': series.quantile(0.25),    # Primer cuartil (25% de datos debajo)\n",
    "        'Q2 (50%)': series.quantile(0.50),    # Segundo cuartil (mediana)\n",
    "        'Q3 (75%)': series.quantile(0.75),    # Tercer cuartil (75% de datos debajo)\n",
    "        'Max': series.max(),                  # Valor m√°ximo observado\n",
    "        'P5': series.quantile(0.05),          # Percentil 5 (l√≠mite inferior robusto)\n",
    "        'P10': series.quantile(0.10),         # Percentil 10\n",
    "        'P90': series.quantile(0.90),         # Percentil 90\n",
    "        'P95': series.quantile(0.95),         # Percentil 95 (l√≠mite superior robusto)\n",
    "        'IQR': series.quantile(0.75) - series.quantile(0.25),  # Rango intercuart√≠lico\n",
    "        'Skewness': series.skew(),            # Asimetr√≠a de la distribuci√≥n\n",
    "        'Kurtosis': series.kurtosis(),        # Curtosis (forma de la distribuci√≥n)\n",
    "        'CV (%)': (series.std() / series.mean() * 100) if series.mean() != 0 else 0  # Coeficiente de variaci√≥n\n",
    "    })\n",
    "\n",
    "# Aplicar funci√≥n a todas las columnas num√©ricas usando apply()\n",
    "# Esto es m√°s eficiente que iterar con bucles for\n",
    "extended_stats = train_raw[numeric_cols].apply(compute_extended_stats).T\n",
    "extended_stats.insert(0, 'Variable', extended_stats.index)\n",
    "extended_stats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Mostrar tabla completa de estad√≠sticas en formato legible\n",
    "print(\"\\nTabla de Estad√≠sticas Descriptivas Extendidas:\")\n",
    "print(extended_stats.to_string(index=False))\n",
    "\n",
    "# Guardar estad√≠sticas a CSV para documentaci√≥n de la tesis y an√°lisis posterior\n",
    "extended_stats.to_csv('../data/processed/extended_statistics.csv', index=False)\n",
    "print(\"\\n‚úÖ Estad√≠sticas guardadas en: data/processed/extended_statistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AN√ÅLISIS DE ASIMETR√çA Y CURTOSIS\n",
    "# =============================================================================\n",
    "# Evaluar la forma de las distribuciones de las variables num√©ricas\n",
    "# Estos an√°lisis son fundamentales para decidir qu√© t√©cnicas de modelado aplicar\n",
    "#\n",
    "# SKEWNESS (Asimetr√≠a): \n",
    "#   - Mide si la distribuci√≥n est√° sesgada hacia la izquierda o derecha\n",
    "#   - Valores cercanos a 0 indican simetr√≠a\n",
    "#   - Valores positivos indican cola hacia la derecha (valores altos)\n",
    "#   - Valores negativos indican cola hacia la izquierda (valores bajos)\n",
    "#\n",
    "# KURTOSIS (Curtosis): \n",
    "#   - Mide qu√© tan puntiaguda o aplanada es la distribuci√≥n\n",
    "#   - Valores cercanos a 0 indican forma similar a distribuci√≥n normal\n",
    "#   - Valores positivos indican distribuci√≥n con pico alto y colas pesadas\n",
    "#   - Valores negativos indican distribuci√≥n aplanada\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AN√ÅLISIS DE ASIMETR√çA Y CURTOSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Funci√≥n para interpretar asimetr√≠a\n",
    "def interpret_skewness(skew):\n",
    "    \"\"\"Interpreta el valor de asimetr√≠a seg√∫n est√°ndares estad√≠sticos.\"\"\"\n",
    "    if skew > 1:\n",
    "        return \"Distribuci√≥n FUERTEMENTE asim√©trica a la DERECHA (cola larga hacia valores altos)\"\n",
    "    elif skew > 0.5:\n",
    "        return \"Distribuci√≥n MODERADAMENTE asim√©trica a la DERECHA\"\n",
    "    elif skew < -1:\n",
    "        return \"Distribuci√≥n FUERTEMENTE asim√©trica a la IZQUIERDA (cola larga hacia valores bajos)\"\n",
    "    elif skew < -0.5:\n",
    "        return \"Distribuci√≥n MODERADAMENTE asim√©trica a la IZQUIERDA\"\n",
    "    else:\n",
    "        return \"Distribuci√≥n APROXIMADAMENTE SIM√âTRICA\"\n",
    "\n",
    "# Funci√≥n para interpretar curtosis\n",
    "def interpret_kurtosis(kurt):\n",
    "    \"\"\"Interpreta el valor de curtosis (pandas usa excess kurtosis: kurtosis - 3).\"\"\"\n",
    "    if kurt > 3:\n",
    "        return \"Distribuci√≥n LEPTOC√öRTICA (pico alto, colas pesadas)\"\n",
    "    elif kurt < -3:\n",
    "        return \"Distribuci√≥n PLATIC√öRTICA (pico bajo, colas ligeras)\"\n",
    "    else:\n",
    "        return \"Distribuci√≥n MESOC√öRTICA (similar a normal)\"\n",
    "\n",
    "# Calcular asimetr√≠a y curtosis usando apply()\n",
    "skew_kurt_analysis = train_raw[numeric_cols].apply(\n",
    "    lambda col: pd.Series({\n",
    "        'Skewness': col.skew(),\n",
    "        'Kurtosis': col.kurtosis(),\n",
    "        'Skew_Interpretation': interpret_skewness(col.skew()),\n",
    "        'Kurt_Interpretation': interpret_kurtosis(col.kurtosis())\n",
    "    })\n",
    ").T\n",
    "\n",
    "# Mostrar resultados formateados\n",
    "for var in numeric_cols:\n",
    "    skew = skew_kurt_analysis.loc[var, 'Skewness']\n",
    "    kurt = skew_kurt_analysis.loc[var, 'Kurtosis']\n",
    "    skew_interp = skew_kurt_analysis.loc[var, 'Skew_Interpretation']\n",
    "    kurt_interp = skew_kurt_analysis.loc[var, 'Kurt_Interpretation']\n",
    "    \n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"  - Asimetr√≠a (Skewness): {skew:.4f}\")\n",
    "    print(f\"    ‚Üí {skew_interp}\")\n",
    "    print(f\"  - Curtosis: {kurt:.4f}\")\n",
    "    print(f\"    ‚Üí {kurt_interp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26533bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DETECCI√ìN DE OUTLIERS - M√âTODO IQR (RANGO INTERCUART√çLICO)\n",
    "# =============================================================================\n",
    "# Aplicar el m√©todo IQR (Interquartile Range) para identificar valores at√≠picos\n",
    "# \n",
    "# M√âTODO IQR:\n",
    "#   - Es un m√©todo estad√≠stico robusto y ampliamente utilizado\n",
    "#   - No asume normalidad en los datos\n",
    "#   - Basado en la regla de Tukey (1977)\n",
    "#\n",
    "# CRITERIO:\n",
    "#   - Un valor es outlier si: valor < Q1 - 1.5*IQR  o  valor > Q3 + 1.5*IQR\n",
    "#   - Q1 = Primer cuartil (percentil 25)\n",
    "#   - Q3 = Tercer cuartil (percentil 75)\n",
    "#   - IQR = Q3 - Q1 (rango intercuart√≠lico)\n",
    "#\n",
    "# INTERPRETACI√ìN:\n",
    "#   - % outliers < 1%: bajo, t√≠picamente aceptable\n",
    "#   - 1% < % outliers < 5%: moderado, requiere an√°lisis\n",
    "#   - % outliers > 5%: alto, posible problema en los datos\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETECCI√ìN DE OUTLIERS - M√âTODO IQR\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Funci√≥n para detectar outliers usando m√©todo IQR\n",
    "def detect_outliers_iqr(series):\n",
    "    \"\"\"Detecta outliers usando el m√©todo IQR (Interquartile Range).\"\"\"\n",
    "    # Calcular cuartiles y rango intercuart√≠lico\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Calcular l√≠mites para detecci√≥n de outliers (regla de 1.5*IQR de Tukey)\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Identificar observaciones fuera de los l√≠mites\n",
    "    outliers_mask = (series < lower_bound) | (series > upper_bound)\n",
    "    n_outliers = outliers_mask.sum()\n",
    "    pct_outliers = (n_outliers / len(series)) * 100\n",
    "    \n",
    "    # Clasificar severidad del porcentaje de outliers\n",
    "    if pct_outliers > 5:\n",
    "        severity = \"‚ö†Ô∏è ALTO porcentaje de outliers (>5%) - Requiere investigaci√≥n\"\n",
    "    elif pct_outliers > 1:\n",
    "        severity = \"‚ö° Porcentaje moderado de outliers - Revisar contexto\"\n",
    "    else:\n",
    "        severity = \"‚úÖ Bajo porcentaje de outliers - Aceptable\"\n",
    "    \n",
    "    return pd.Series({\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'N¬∞ Outliers': n_outliers,\n",
    "        '% Outliers': pct_outliers,\n",
    "        'Severity': severity\n",
    "    })\n",
    "\n",
    "# Aplicar funci√≥n de detecci√≥n de outliers a todas las columnas num√©ricas\n",
    "outliers_df = train_raw[numeric_cols].apply(detect_outliers_iqr).T\n",
    "outliers_df.insert(0, 'Variable', outliers_df.index)\n",
    "outliers_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Mostrar resultados detallados por variable\n",
    "for var in numeric_cols:\n",
    "    row = outliers_df[outliers_df['Variable'] == var].iloc[0]\n",
    "    \n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"  - Q1: {row['Q1']:.2f}\")\n",
    "    print(f\"  - Q3: {row['Q3']:.2f}\")\n",
    "    print(f\"  - IQR: {row['IQR']:.2f}\")\n",
    "    print(f\"  - L√≠mite inferior: {row['Lower Bound']:.2f}\")\n",
    "    print(f\"  - L√≠mite superior: {row['Upper Bound']:.2f}\")\n",
    "    print(f\"  - Outliers detectados: {int(row['N¬∞ Outliers'])} ({row['% Outliers']:.2f}%)\")\n",
    "    print(f\"  {row['Severity']}\")\n",
    "\n",
    "# Mostrar resumen completo\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN DE OUTLIERS:\")\n",
    "print(outliers_df.to_string(index=False))\n",
    "\n",
    "# Guardar an√°lisis de outliers para documentaci√≥n de la tesis\n",
    "outliers_df.to_csv('../data/processed/outliers_analysis.csv', index=False)\n",
    "print(\"\\n‚úÖ An√°lisis de outliers guardado en: data/processed/outliers_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AN√ÅLISIS DE VARIABLE CATEG√ìRICA: SEX\n",
    "# =============================================================================\n",
    "# Analizar la distribuci√≥n de la √∫nica variable categ√≥rica en el dataset\n",
    "# Es crucial verificar el balance entre categor√≠as para evitar sesgos en el modelo\n",
    "#\n",
    "# IMPORTANCIA DEL BALANCE:\n",
    "#   - Un dataset desbalanceado puede producir modelos sesgados\n",
    "#   - Diferencia < 5%: balanceado (ideal)\n",
    "#   - 5% < Diferencia < 15%: ligero desbalance (aceptable)\n",
    "#   - Diferencia > 15%: desbalanceado (requiere t√©cnicas de balanceo)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AN√ÅLISIS DE VARIABLE CATEG√ìRICA: SEX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular frecuencias absolutas y relativas\n",
    "sex_counts = train_raw['Sex'].value_counts()                    # Conteo absoluto por categor√≠a\n",
    "sex_pct = train_raw['Sex'].value_counts(normalize=True) * 100   # Porcentaje de cada categor√≠a\n",
    "\n",
    "# Mostrar distribuci√≥n de g√©nero en el dataset\n",
    "print(\"\\nDistribuci√≥n de G√©nero:\")\n",
    "print(f\"  - Female: {sex_counts.get('female', 0)} ({sex_pct.get('female', 0):.2f}%)\")\n",
    "print(f\"  - Male: {sex_counts.get('male', 0)} ({sex_pct.get('male', 0):.2f}%)\")\n",
    "\n",
    "# Evaluar el balance del dataset\n",
    "# Un dataset balanceado (diferencia <5%) reduce el riesgo de sesgo en los modelos\n",
    "# y evita que el modelo aprenda patrones espurios relacionados con la clase mayoritaria\n",
    "diff = abs(sex_pct.get('female', 0) - sex_pct.get('male', 0))\n",
    "\n",
    "if diff < 5:\n",
    "    print(f\"\\n‚úÖ Dataset BALANCEADO por g√©nero (diferencia: {diff:.2f}%)\")\n",
    "    print(f\"   ‚Üí No se requieren t√©cnicas de balanceo de clases\")\n",
    "elif diff < 15:\n",
    "    print(f\"\\n‚ö° Dataset con LIGERO desbalance por g√©nero (diferencia: {diff:.2f}%)\")\n",
    "    print(f\"   ‚Üí Monitorear durante el modelado, puede no requerir correcci√≥n\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Dataset DESBALANCEADO por g√©nero (diferencia: {diff:.2f}%)\")\n",
    "    print(f\"   ‚Üí Considerar: SMOTE, oversampling, undersampling, o pesos de clase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dcffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# S√çNTESIS DE CALIDAD DE DATOS\n",
    "# =============================================================================\n",
    "# Consolidar todos los hallazgos del an√°lisis exploratorio inicial\n",
    "# Evaluar fortalezas, debilidades y caracter√≠sticas generales del dataset\n",
    "# Proporcionar recomendaciones para las siguientes etapas del proyecto\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRIMERAS OBSERVACIONES SOBRE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. FORTALEZAS DEL DATASET\n",
    "# =============================================================================\n",
    "print(\"\\n‚úÖ FORTALEZAS DEL DATASET:\")\n",
    "print(\"  1. Sin valores nulos (0% missing data)\")\n",
    "print(\"     ‚Üí No se requiere imputaci√≥n compleja\")\n",
    "print(\"  2. Dataset de gran tama√±o (750,000 registros)\")\n",
    "print(\"     ‚Üí Suficiente para entrenar modelos complejos y obtener resultados robustos\")\n",
    "print(\"  3. Distribuci√≥n balanceada por g√©nero (~50/50)\")\n",
    "print(\"     ‚Üí No hay sesgo por clase en la variable Sex\")\n",
    "print(\"  4. Tipos de datos correctos y consistentes\")\n",
    "print(\"     ‚Üí No se requieren conversiones complejas\")\n",
    "print(\"  5. Rangos de valores dentro de l√≠mites fisiol√≥gicos\")\n",
    "print(\"     ‚Üí Los datos parecen realistas y v√°lidos para modelado\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. OBSERVACIONES Y PRECAUCIONES\n",
    "# =============================================================================\n",
    "print(\"\\n‚ö†Ô∏è OBSERVACIONES Y PRECAUCIONES:\")\n",
    "\n",
    "# Verificar si hay variables con alto porcentaje de outliers\n",
    "high_outliers = outliers_df[outliers_df['% Outliers'] > 5]\n",
    "if len(high_outliers) > 0:\n",
    "    print(f\"  1. Variables con alto % de outliers: {', '.join(high_outliers['Variable'].tolist())}\")\n",
    "    print(f\"     ‚Üí Evaluar si son valores v√°lidos o errores de medici√≥n\")\n",
    "    print(f\"     ‚Üí Considerar transformaciones o winsorizaci√≥n\")\n",
    "else:\n",
    "    print(\"  1. Bajo porcentaje de outliers en todas las variables\")\n",
    "    print(\"     ‚Üí Los datos son consistentes y de buena calidad\")\n",
    "\n",
    "# Verificar variables con asimetr√≠a significativa\n",
    "skew_values = {col: train_raw[col].skew() for col in numeric_cols}\n",
    "high_skew = [col for col, skew in skew_values.items() if abs(skew) > 1]\n",
    "if high_skew:\n",
    "    print(f\"  2. Variables con alta asimetr√≠a: {', '.join(high_skew)}\")\n",
    "    print(f\"     ‚Üí Considerar transformaciones (log, Box-Cox, Yeo-Johnson)\")\n",
    "    print(f\"     ‚Üí Algunos modelos (√°rboles, RF) son robustos a asimetr√≠a\")\n",
    "    print(f\"     ‚Üí Modelos lineales pueden beneficiarse de normalizaci√≥n\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. CARACTER√çSTICAS GENERALES DEL DATASET\n",
    "# =============================================================================\n",
    "print(\"\\nüìä CARACTER√çSTICAS DEL DATASET:\")\n",
    "print(f\"  - Tama√±o total: {len(train_raw):,} registros\")\n",
    "print(f\"  - N√∫mero de variables: {len(train_raw.columns)}\")\n",
    "print(f\"  - Memoria utilizada: {train_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"  - Variables num√©ricas: {len(numeric_cols)}\")\n",
    "print(f\"  - Variables categ√≥ricas: 1 (Sex)\")\n",
    "print(f\"  - Variable objetivo: Calories (regresi√≥n)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. CONCLUSI√ìN Y RECOMENDACIONES\n",
    "# =============================================================================\n",
    "print(\"\\n‚úÖ CONCLUSI√ìN:\")\n",
    "print(\"  El dataset presenta EXCELENTE calidad para an√°lisis y modelado.\")\n",
    "print(\"  No se requiere limpieza extensiva, solo preparaci√≥n est√°ndar.\")\n",
    "print(\"\\nüìã PR√ìXIMOS PASOS RECOMENDADOS:\")\n",
    "print(\"  1. Preparaci√≥n de datos (02_data_preparation.ipynb)\")\n",
    "print(\"     - Codificaci√≥n de variables categ√≥ricas\")\n",
    "print(\"     - Divisi√≥n train/validation/test\")\n",
    "print(\"     - Normalizaci√≥n de features si es necesario\")\n",
    "print(\"  2. An√°lisis exploratorio profundo (03_exploratory_analysis.ipynb)\")\n",
    "print(\"     - Visualizaciones de distribuciones\")\n",
    "print(\"     - An√°lisis de correlaciones\")\n",
    "print(\"     - Identificaci√≥n de relaciones entre variables\")\n",
    "print(\"  3. Feature engineering (04_feature_engineering.ipynb)\")\n",
    "print(\"     - Creaci√≥n de features derivadas (BMI, interacciones, etc.)\")\n",
    "print(\"     - Selecci√≥n de features m√°s relevantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785ec3cdb87d6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:37:17.156197Z",
     "start_time": "2025-09-14T14:37:17.050990Z"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VERIFICACI√ìN DE RANGOS DE VALORES\n",
    "# =============================================================================\n",
    "# Verificar que los valores de todas las variables est√©n dentro de rangos razonables\n",
    "# Esto ayuda a detectar posibles errores de captura o valores inv√°lidos\n",
    "#\n",
    "# RANGOS FISIOL√ìGICOS ESPERADOS (Referencias):\n",
    "#   - Age: 0-120 a√±os (aunque t√≠picamente 10-100 para ejercicio)\n",
    "#   - Height: 100-250 cm (rango humano adulto: ~140-220 cm)\n",
    "#   - Weight: 20-200 kg (rango humano adulto: ~40-150 kg)\n",
    "#   - Duration: 1-180 minutos (sesiones de ejercicio t√≠picas)\n",
    "#   - Heart_Rate: 40-220 BPM (reposo: ~60-100, m√°ximo: 220-edad)\n",
    "#   - Body_Temp: 35-42¬∞C (normal: 36.5-37.5, ejercicio: hasta 40¬∞C)\n",
    "#   - Calories: 1-1000 kcal (depende de intensidad y duraci√≥n)\n",
    "\n",
    "# Verificar valores √∫nicos de la variable categ√≥rica\n",
    "print('Sex unique:', train_raw['Sex'].unique())\n",
    "print('  ‚Üí Solo dos valores (male/female): ‚úÖ Correcto')\n",
    "\n",
    "# Definir rangos esperados para cada variable\n",
    "# Formato: 'Variable': (min_esperado, max_esperado)\n",
    "expected_ranges = {\n",
    "    'Age': (10, 100),\n",
    "    'Height': (100, 250),\n",
    "    'Weight': (20, 200),\n",
    "    'Duration': (1, 180),\n",
    "    'Heart_Rate': (40, 220),\n",
    "    'Body_Temp': (35, 42),\n",
    "    'Calories': (1, 1000)\n",
    "}\n",
    "\n",
    "# Funci√≥n para validar rangos de una serie\n",
    "def validate_range(series, var_name):\n",
    "    \"\"\"Valida si los valores de una serie est√°n dentro de rangos esperados.\"\"\"\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    \n",
    "    # Obtener rango esperado si est√° definido\n",
    "    if var_name in expected_ranges:\n",
    "        min_expected, max_expected = expected_ranges[var_name]\n",
    "        is_valid = (min_val >= min_expected) and (max_val <= max_expected)\n",
    "        status = \"‚úÖ Rango v√°lido\" if is_valid else \"‚ö†Ô∏è Valores inusuales detectados\"\n",
    "    else:\n",
    "        status = \"‚úÖ Rango v√°lido\"\n",
    "    \n",
    "    return pd.Series({\n",
    "        'Min': min_val,\n",
    "        'Max': max_val,\n",
    "        'Status': status\n",
    "    })\n",
    "\n",
    "# Aplicar validaci√≥n de rangos a todas las columnas num√©ricas\n",
    "range_validation = train_raw[numeric_cols].apply(lambda col: validate_range(col, col.name)).T\n",
    "\n",
    "# Mostrar resultados formateados\n",
    "print('\\nRangos de Variables Num√©ricas:')\n",
    "for var in numeric_cols:\n",
    "    min_val = range_validation.loc[var, 'Min']\n",
    "    max_val = range_validation.loc[var, 'Max']\n",
    "    status = range_validation.loc[var, 'Status']\n",
    "    \n",
    "    print(f'{var:12s}: min = {min_val:7.1f}, max = {max_val:7.1f}  {status}')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('CONCLUSI√ìN DE VERIFICACI√ìN DE RANGOS:')\n",
    "if all('‚úÖ' in status for status in range_validation['Status']):\n",
    "    print('  ‚úÖ Todos los valores est√°n dentro de rangos fisiol√≥gicos razonables')\n",
    "    print('  ‚úÖ No se detectaron errores evidentes en la captura de datos')\n",
    "else:\n",
    "    print('  ‚ö†Ô∏è Se detectaron algunas variables con valores fuera de rangos esperados')\n",
    "    print('  ‚ö†Ô∏è Revisar variables marcadas para validar si son errores o casos excepcionales')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5c956954319a9",
   "metadata": {},
   "source": [
    "## Conclusiones del An√°lisis de Data Understanding\n",
    "\n",
    "### Hallazgos Principales:\n",
    "\n",
    "1. **Calidad de Datos**: El dataset presenta **excelente calidad**:\n",
    "   - ‚úÖ 0% valores nulos (sin missing data)\n",
    "   - ‚úÖ 0 registros duplicados\n",
    "   - ‚úÖ Tipos de datos correctos y consistentes\n",
    "   - ‚úÖ Rangos de valores dentro de l√≠mites fisiol√≥gicos\n",
    "\n",
    "2. **Estructura del Dataset**:\n",
    "   - `train.csv`: 750,000 registros √ó 9 columnas (incluye variable objetivo `Calories`)\n",
    "   - `test.csv`: 250,000 registros √ó 8 columnas (sin `Calories`)\n",
    "   - **Variables num√©ricas**: Age, Height, Weight, Duration, Heart_Rate, Body_Temp, Calories\n",
    "   - **Variables categ√≥ricas**: Sex (male/female)\n",
    "\n",
    "3. **Balance del Dataset**:\n",
    "   - Distribuci√≥n de g√©nero perfectamente balanceada: 50.10% Female / 49.90% Male\n",
    "   - No se requieren t√©cnicas de balanceo de clases\n",
    "\n",
    "4. **Outliers Detectados**:\n",
    "   - Body_Temp: 1.99% outliers (14,919 registros) - Porcentaje moderado\n",
    "   - Otras variables: < 0.02% outliers - Porcentaje bajo y aceptable\n",
    "\n",
    "5. **Caracter√≠sticas de Distribuciones**:\n",
    "   - La mayor√≠a de variables tienen distribuciones **aproximadamente sim√©tricas**\n",
    "   - Body_Temp: Asimetr√≠a fuerte a la izquierda (-1.02)\n",
    "   - Calories: Asimetr√≠a moderada a la derecha (0.54)\n",
    "\n",
    "### Implicaciones para el Modelado:\n",
    "\n",
    "- ‚úÖ Dataset **listo para Machine Learning** sin necesidad de limpieza extensiva\n",
    "- ‚úÖ Gran tama√±o muestral permite entrenar modelos complejos con alta confianza\n",
    "- ‚ö° Considerar transformaciones para variables asim√©tricas (Body_Temp, Calories)\n",
    "- ‚ö° Evaluar tratamiento de outliers en Body_Temp seg√∫n contexto del problema\n",
    "\n",
    "### Pr√≥ximos Pasos:\n",
    "\n",
    "1. **02_data_preparation.ipynb**: Limpieza y preparaci√≥n de datos\n",
    "   - Codificaci√≥n de variables categ√≥ricas (One-Hot Encoding)\n",
    "   - Divisi√≥n train/validation/test\n",
    "   - Gesti√≥n de outliers si es necesario\n",
    "\n",
    "2. **03_exploratory_analysis.ipynb**: An√°lisis exploratorio profundo\n",
    "   - Visualizaciones detalladas de distribuciones\n",
    "   - An√°lisis de correlaciones entre variables\n",
    "   - Identificaci√≥n de relaciones con la variable objetivo\n",
    "\n",
    "3. **04_feature_engineering.ipynb**: Ingenier√≠a de caracter√≠sticas\n",
    "   - Creaci√≥n de features derivadas (BMI, ratios, interacciones)\n",
    "   - Normalizaci√≥n/estandarizaci√≥n de features\n",
    "   - Selecci√≥n de features m√°s relevantes\n",
    "\n",
    "---\n",
    "\n",
    "**Estado**: ‚úÖ Data Understanding completado satisfactoriamente  \n",
    "**Dataset**: Aprobado para continuar con el pipeline de Machine Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
