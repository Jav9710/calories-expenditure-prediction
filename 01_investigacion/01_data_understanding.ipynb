{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33603ced2755bea0",
   "metadata": {},
   "source": "# 01 - Data Understanding\n\n## Objetivo del Notebook\nEste notebook realiza una **revisi√≥n inicial (Data Understanding)** del dataset disponible para el proyecto de predicci√≥n de calor√≠as quemadas durante el ejercicio f√≠sico.\n\n**Objetivos espec√≠ficos**:\n1. Confirmar el esquema y estructura de los datos\n2. Identificar tipos de datos de cada variable\n3. Detectar valores faltantes (missing values)\n4. Calcular estad√≠sticas descriptivas completas\n5. Analizar distribuciones y caracter√≠sticas de las variables\n6. Detectar valores at√≠picos (outliers)\n7. Evaluar la calidad general del dataset\n\n**Contexto del proyecto**: Desarrollo de un modelo de Machine Learning para predecir el gasto energ√©tico (calor√≠as) durante actividad f√≠sica basado en variables biom√©tricas y fisiol√≥gicas medibles."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T22:12:34.799289Z",
     "start_time": "2025-09-30T22:12:34.420659Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_CSV: ..\\data\\raw\\train.csv\n",
      "TEST_CSV: ..\\data\\raw\\test.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "TRAIN_CSV = DATA_DIR / \"raw\" / \"train.csv\"\n",
    "TEST_CSV = DATA_DIR / \"raw\" / \"test.csv\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"TRAIN_CSV: {TRAIN_CSV}\")\n",
    "print(f\"TEST_CSV: {TEST_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92cefc5a6440c9bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T22:12:38.401443Z",
     "start_time": "2025-09-30T22:12:37.808906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (750000, 9)\n",
      "Test shape: (250000, 8)\n",
      "Train columns: ['id', 'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']\n",
      "Test columns: ['id', 'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>189.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>163.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>51</td>\n",
       "      <td>161.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>192.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>166.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Sex  Age  Height  Weight  Duration  Heart_Rate  Body_Temp  Calories\n",
       "0   0    male   36   189.0    82.0      26.0       101.0       41.0     150.0\n",
       "1   1  female   64   163.0    60.0       8.0        85.0       39.7      34.0\n",
       "2   2  female   51   161.0    64.0       7.0        84.0       39.8      29.0\n",
       "3   3    male   20   192.0    90.0      25.0       105.0       40.7     140.0\n",
       "4   4  female   38   166.0    61.0      25.0       102.0       40.6     146.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar archivos\n",
    "train_raw = pd.read_csv(TRAIN_CSV)\n",
    "test_raw = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(\"Train shape:\", train_raw.shape)\n",
    "print(\"Test shape:\", test_raw.shape)\n",
    "print(\"Train columns:\", train_raw.columns.tolist())\n",
    "print(\"Test columns:\", test_raw.columns.tolist())\n",
    "\n",
    "# Previsualizar\n",
    "display(train_raw.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3405081c4b1f8bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:37:00.032153Z",
     "start_time": "2025-09-14T14:36:59.789673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   id          750000 non-null  int64  \n",
      " 1   Sex         750000 non-null  object \n",
      " 2   Age         750000 non-null  int64  \n",
      " 3   Height      750000 non-null  float64\n",
      " 4   Weight      750000 non-null  float64\n",
      " 5   Duration    750000 non-null  float64\n",
      " 6   Heart_Rate  750000 non-null  float64\n",
      " 7   Body_Temp   750000 non-null  float64\n",
      " 8   Calories    750000 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 51.5+ MB\n",
      "None\n",
      "\n",
      "Nulos por columna (train):\n",
      " id            0\n",
      "Sex           0\n",
      "Age           0\n",
      "Height        0\n",
      "Weight        0\n",
      "Duration      0\n",
      "Heart_Rate    0\n",
      "Body_Temp     0\n",
      "Calories      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Informaci√≥n y nulos (solo train, porque tiene target)\n",
    "print(train_raw.info())\n",
    "print(\"\\nNulos por columna (train):\\n\", train_raw.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf409278118602a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:37:09.087513Z",
     "start_time": "2025-09-14T14:37:08.648814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374999.5</td>\n",
       "      <td>216506.495284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187499.75</td>\n",
       "      <td>374999.5</td>\n",
       "      <td>562499.25</td>\n",
       "      <td>749999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>750000</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>375721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.420404</td>\n",
       "      <td>15.175049</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.697685</td>\n",
       "      <td>12.824496</td>\n",
       "      <td>126.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.145668</td>\n",
       "      <td>13.982704</td>\n",
       "      <td>36.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.421015</td>\n",
       "      <td>8.354095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart_Rate</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.483995</td>\n",
       "      <td>9.449845</td>\n",
       "      <td>67.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Body_Temp</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.036253</td>\n",
       "      <td>0.779875</td>\n",
       "      <td>37.1</td>\n",
       "      <td>39.6</td>\n",
       "      <td>40.3</td>\n",
       "      <td>40.7</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calories</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.282781</td>\n",
       "      <td>62.395349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count unique     top    freq        mean            std    min  \\\n",
       "id          750000.0    NaN     NaN     NaN    374999.5  216506.495284    0.0   \n",
       "Sex           750000      2  female  375721         NaN            NaN    NaN   \n",
       "Age         750000.0    NaN     NaN     NaN   41.420404      15.175049   20.0   \n",
       "Height      750000.0    NaN     NaN     NaN  174.697685      12.824496  126.0   \n",
       "Weight      750000.0    NaN     NaN     NaN   75.145668      13.982704   36.0   \n",
       "Duration    750000.0    NaN     NaN     NaN   15.421015       8.354095    1.0   \n",
       "Heart_Rate  750000.0    NaN     NaN     NaN   95.483995       9.449845   67.0   \n",
       "Body_Temp   750000.0    NaN     NaN     NaN   40.036253       0.779875   37.1   \n",
       "Calories    750000.0    NaN     NaN     NaN   88.282781      62.395349    1.0   \n",
       "\n",
       "                  25%       50%        75%       max  \n",
       "id          187499.75  374999.5  562499.25  749999.0  \n",
       "Sex               NaN       NaN        NaN       NaN  \n",
       "Age              28.0      40.0       52.0      79.0  \n",
       "Height          164.0     174.0      185.0     222.0  \n",
       "Weight           63.0      74.0       87.0     132.0  \n",
       "Duration          8.0      15.0       23.0      30.0  \n",
       "Heart_Rate       88.0      95.0      103.0     128.0  \n",
       "Body_Temp        39.6      40.3       40.7      41.5  \n",
       "Calories         34.0      77.0      136.0     314.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estad√≠sticas descriptivas (train)\n",
    "display(train_raw.describe(include='all').T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0f37d",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# ESTAD√çSTICAS DESCRIPTIVAS EXTENDIDAS\n# =============================================================================\n# Generar un an√°lisis estad√≠stico m√°s completo que el m√©todo .describe() b√°sico\n# Incluye m√©tricas adicionales relevantes para an√°lisis de datos cient√≠ficos y tesis\n\nprint(\"=\" * 80)\nprint(\"ESTAD√çSTICAS DESCRIPTIVAS EXTENDIDAS\")\nprint(\"=\" * 80)\n\n# Seleccionar solo columnas num√©ricas para an√°lisis cuantitativo\n# Se excluye 'id' ya que es solo un identificador sin valor estad√≠stico\nnumeric_cols = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']\n\n# Crear DataFrame para almacenar todas las estad√≠sticas extendidas\nextended_stats = pd.DataFrame()\n\n# Calcular estad√≠sticas comprehensivas para cada variable num√©rica\nfor col in numeric_cols:\n    stats = {\n        'Variable': col,\n        'Count': train_raw[col].count(),              # N√∫mero de observaciones no nulas\n        'Mean': train_raw[col].mean(),                # Media aritm√©tica\n        'Median': train_raw[col].median(),            # Mediana (percentil 50, robusto a outliers)\n        'Std': train_raw[col].std(),                  # Desviaci√≥n est√°ndar (dispersi√≥n)\n        'Min': train_raw[col].min(),                  # Valor m√≠nimo observado\n        'Q1 (25%)': train_raw[col].quantile(0.25),    # Primer cuartil (25% de datos debajo)\n        'Q2 (50%)': train_raw[col].quantile(0.50),    # Segundo cuartil (mediana)\n        'Q3 (75%)': train_raw[col].quantile(0.75),    # Tercer cuartil (75% de datos debajo)\n        'Max': train_raw[col].max(),                  # Valor m√°ximo observado\n        'P5': train_raw[col].quantile(0.05),          # Percentil 5 (l√≠mite inferior robusto)\n        'P10': train_raw[col].quantile(0.10),         # Percentil 10\n        'P90': train_raw[col].quantile(0.90),         # Percentil 90\n        'P95': train_raw[col].quantile(0.95),         # Percentil 95 (l√≠mite superior robusto)\n        'IQR': train_raw[col].quantile(0.75) - train_raw[col].quantile(0.25),  # Rango intercuart√≠lico\n        'Skewness': train_raw[col].skew(),            # Asimetr√≠a de la distribuci√≥n\n        'Kurtosis': train_raw[col].kurtosis(),        # Curtosis (forma de la distribuci√≥n)\n        'CV (%)': (train_raw[col].std() / train_raw[col].mean() * 100) if train_raw[col].mean() != 0 else 0  # Coeficiente de variaci√≥n\n    }\n    extended_stats = pd.concat([extended_stats, pd.DataFrame([stats])], ignore_index=True)\n\n# Mostrar tabla completa de estad√≠sticas en formato legible\nprint(\"\\nTabla de Estad√≠sticas Descriptivas Extendidas:\")\nprint(extended_stats.to_string(index=False))\n\n# Guardar estad√≠sticas a CSV para documentaci√≥n de la tesis y an√°lisis posterior\nextended_stats.to_csv('../data/processed/extended_statistics.csv', index=False)\nprint(\"\\n‚úÖ Estad√≠sticas guardadas en: data/processed/extended_statistics.csv\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2815a",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# AN√ÅLISIS DE ASIMETR√çA Y CURTOSIS\n# =============================================================================\n# Evaluar la forma de las distribuciones de las variables num√©ricas\n# Estos an√°lisis son fundamentales para decidir qu√© t√©cnicas de modelado aplicar\n#\n# SKEWNESS (Asimetr√≠a): \n#   - Mide si la distribuci√≥n est√° sesgada hacia la izquierda o derecha\n#   - Valores cercanos a 0 indican simetr√≠a\n#   - Valores positivos indican cola hacia la derecha (valores altos)\n#   - Valores negativos indican cola hacia la izquierda (valores bajos)\n#\n# KURTOSIS (Curtosis): \n#   - Mide qu√© tan puntiaguda o aplanada es la distribuci√≥n\n#   - Valores cercanos a 0 indican forma similar a distribuci√≥n normal\n#   - Valores positivos indican distribuci√≥n con pico alto y colas pesadas\n#   - Valores negativos indican distribuci√≥n aplanada\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"AN√ÅLISIS DE ASIMETR√çA Y CURTOSIS\")\nprint(\"=\" * 80)\n\nfor col in numeric_cols:\n    # Calcular m√©tricas de forma de distribuci√≥n\n    skew = train_raw[col].skew()    # Asimetr√≠a\n    kurt = train_raw[col].kurtosis()  # Curtosis (usando definici√≥n de pandas: excess kurtosis)\n\n    print(f\"\\n{col}:\")\n    print(f\"  - Asimetr√≠a (Skewness): {skew:.4f}\")\n\n    # Interpretar valores de asimetr√≠a seg√∫n est√°ndares estad√≠sticos\n    # Skewness > 0: cola hacia la derecha (valores altos)\n    # Skewness < 0: cola hacia la izquierda (valores bajos)\n    # |Skewness| < 0.5: aproximadamente sim√©trica\n    # 0.5 < |Skewness| < 1: moderadamente asim√©trica\n    # |Skewness| > 1: fuertemente asim√©trica\n    if skew > 1:\n        print(f\"    ‚Üí Distribuci√≥n FUERTEMENTE asim√©trica a la DERECHA (cola larga hacia valores altos)\")\n    elif skew > 0.5:\n        print(f\"    ‚Üí Distribuci√≥n MODERADAMENTE asim√©trica a la DERECHA\")\n    elif skew < -1:\n        print(f\"    ‚Üí Distribuci√≥n FUERTEMENTE asim√©trica a la IZQUIERDA (cola larga hacia valores bajos)\")\n    elif skew < -0.5:\n        print(f\"    ‚Üí Distribuci√≥n MODERADAMENTE asim√©trica a la IZQUIERDA\")\n    else:\n        print(f\"    ‚Üí Distribuci√≥n APROXIMADAMENTE SIM√âTRICA\")\n\n    print(f\"  - Curtosis: {kurt:.4f}\")\n\n    # Interpretar valores de curtosis (pandas usa excess kurtosis: kurtosis - 3)\n    # Kurtosis > 3: leptoc√∫rtica (pico alto, colas pesadas, m√°s outliers)\n    # Kurtosis < -3: platic√∫rtica (pico bajo, colas ligeras, menos outliers)\n    # -3 <= Kurtosis <= 3: mesoc√∫rtica (similar a distribuci√≥n normal)\n    if kurt > 3:\n        print(f\"    ‚Üí Distribuci√≥n LEPTOC√öRTICA (pico alto, colas pesadas)\")\n    elif kurt < -3:\n        print(f\"    ‚Üí Distribuci√≥n PLATIC√öRTICA (pico bajo, colas ligeras)\")\n    else:\n        print(f\"    ‚Üí Distribuci√≥n MESOC√öRTICA (similar a normal)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26533bb3",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DETECCI√ìN DE OUTLIERS - M√âTODO IQR (RANGO INTERCUART√çLICO)\n# =============================================================================\n# Aplicar el m√©todo IQR (Interquartile Range) para identificar valores at√≠picos\n# \n# M√âTODO IQR:\n#   - Es un m√©todo estad√≠stico robusto y ampliamente utilizado\n#   - No asume normalidad en los datos\n#   - Basado en la regla de Tukey (1977)\n#\n# CRITERIO:\n#   - Un valor es outlier si: valor < Q1 - 1.5*IQR  o  valor > Q3 + 1.5*IQR\n#   - Q1 = Primer cuartil (percentil 25)\n#   - Q3 = Tercer cuartil (percentil 75)\n#   - IQR = Q3 - Q1 (rango intercuart√≠lico)\n#\n# INTERPRETACI√ìN:\n#   - % outliers < 1%: bajo, t√≠picamente aceptable\n#   - 1% < % outliers < 5%: moderado, requiere an√°lisis\n#   - % outliers > 5%: alto, posible problema en los datos\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"DETECCI√ìN DE OUTLIERS - M√âTODO IQR\")\nprint(\"=\" * 80)\n\noutliers_summary = []  # Lista para almacenar resumen de outliers por variable\n\n# Analizar cada variable num√©rica individualmente\nfor col in numeric_cols:\n    # Paso 1: Calcular cuartiles y rango intercuart√≠lico\n    Q1 = train_raw[col].quantile(0.25)  # Primer cuartil (25%)\n    Q3 = train_raw[col].quantile(0.75)  # Tercer cuartil (75%)\n    IQR = Q3 - Q1                        # Rango intercuart√≠lico (dispersi√≥n)\n\n    # Paso 2: Calcular l√≠mites para detecci√≥n de outliers (regla de 1.5*IQR de Tukey)\n    lower_bound = Q1 - 1.5 * IQR  # L√≠mite inferior: valores por debajo son outliers\n    upper_bound = Q3 + 1.5 * IQR  # L√≠mite superior: valores por encima son outliers\n\n    # Paso 3: Identificar observaciones fuera de los l√≠mites\n    outliers = train_raw[(train_raw[col] < lower_bound) | (train_raw[col] > upper_bound)]\n    n_outliers = len(outliers)                        # N√∫mero absoluto de outliers\n    pct_outliers = (n_outliers / len(train_raw)) * 100  # Porcentaje de outliers\n\n    # Paso 4: Almacenar resultados en estructura de datos\n    outliers_summary.append({\n        'Variable': col,\n        'Q1': Q1,\n        'Q3': Q3,\n        'IQR': IQR,\n        'Lower Bound': lower_bound,\n        'Upper Bound': upper_bound,\n        'N¬∞ Outliers': n_outliers,\n        '% Outliers': pct_outliers\n    })\n\n    # Paso 5: Mostrar resultados detallados por variable\n    print(f\"\\n{col}:\")\n    print(f\"  - Q1: {Q1:.2f}\")\n    print(f\"  - Q3: {Q3:.2f}\")\n    print(f\"  - IQR: {IQR:.2f}\")\n    print(f\"  - L√≠mite inferior: {lower_bound:.2f}\")\n    print(f\"  - L√≠mite superior: {upper_bound:.2f}\")\n    print(f\"  - Outliers detectados: {n_outliers} ({pct_outliers:.2f}%)\")\n\n    # Paso 6: Clasificar severidad del porcentaje de outliers\n    if pct_outliers > 5:\n        print(f\"  ‚ö†Ô∏è ALTO porcentaje de outliers (>{5}%) - Requiere investigaci√≥n\")\n    elif pct_outliers > 1:\n        print(f\"  ‚ö° Porcentaje moderado de outliers - Revisar contexto\")\n    else:\n        print(f\"  ‚úÖ Bajo porcentaje de outliers - Aceptable\")\n\n# Crear DataFrame resumen con todos los resultados para an√°lisis global\noutliers_df = pd.DataFrame(outliers_summary)\nprint(\"\\n\" + \"=\" * 80)\nprint(\"RESUMEN DE OUTLIERS:\")\nprint(outliers_df.to_string(index=False))\n\n# Guardar an√°lisis de outliers para documentaci√≥n de la tesis\noutliers_df.to_csv('../data/processed/outliers_analysis.csv', index=False)\nprint(\"\\n‚úÖ An√°lisis de outliers guardado en: data/processed/outliers_analysis.csv\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96869b",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# AN√ÅLISIS DE VARIABLE CATEG√ìRICA: SEX\n# =============================================================================\n# Analizar la distribuci√≥n de la √∫nica variable categ√≥rica en el dataset\n# Es crucial verificar el balance entre categor√≠as para evitar sesgos en el modelo\n#\n# IMPORTANCIA DEL BALANCE:\n#   - Un dataset desbalanceado puede producir modelos sesgados\n#   - Diferencia < 5%: balanceado (ideal)\n#   - 5% < Diferencia < 15%: ligero desbalance (aceptable)\n#   - Diferencia > 15%: desbalanceado (requiere t√©cnicas de balanceo)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"AN√ÅLISIS DE VARIABLE CATEG√ìRICA: SEX\")\nprint(\"=\" * 80)\n\n# Calcular frecuencias absolutas y relativas\nsex_counts = train_raw['Sex'].value_counts()                    # Conteo absoluto por categor√≠a\nsex_pct = train_raw['Sex'].value_counts(normalize=True) * 100   # Porcentaje de cada categor√≠a\n\n# Mostrar distribuci√≥n de g√©nero en el dataset\nprint(\"\\nDistribuci√≥n de G√©nero:\")\nprint(f\"  - Female: {sex_counts.get('female', 0)} ({sex_pct.get('female', 0):.2f}%)\")\nprint(f\"  - Male: {sex_counts.get('male', 0)} ({sex_pct.get('male', 0):.2f}%)\")\n\n# Evaluar el balance del dataset\n# Un dataset balanceado (diferencia <5%) reduce el riesgo de sesgo en los modelos\n# y evita que el modelo aprenda patrones espurios relacionados con la clase mayoritaria\ndiff = abs(sex_pct.get('female', 0) - sex_pct.get('male', 0))\n\nif diff < 5:\n    print(f\"\\n‚úÖ Dataset BALANCEADO por g√©nero (diferencia: {diff:.2f}%)\")\n    print(f\"   ‚Üí No se requieren t√©cnicas de balanceo de clases\")\nelif diff < 15:\n    print(f\"\\n‚ö° Dataset con LIGERO desbalance por g√©nero (diferencia: {diff:.2f}%)\")\n    print(f\"   ‚Üí Monitorear durante el modelado, puede no requerir correcci√≥n\")\nelse:\n    print(f\"\\n‚ö†Ô∏è Dataset DESBALANCEADO por g√©nero (diferencia: {diff:.2f}%)\")\n    print(f\"   ‚Üí Considerar: SMOTE, oversampling, undersampling, o pesos de clase\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dcffa7",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# S√çNTESIS DE CALIDAD DE DATOS\n# =============================================================================\n# Consolidar todos los hallazgos del an√°lisis exploratorio inicial\n# Evaluar fortalezas, debilidades y caracter√≠sticas generales del dataset\n# Proporcionar recomendaciones para las siguientes etapas del proyecto\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PRIMERAS OBSERVACIONES SOBRE CALIDAD DE DATOS\")\nprint(\"=\" * 80)\n\n# =============================================================================\n# 1. FORTALEZAS DEL DATASET\n# =============================================================================\nprint(\"\\n‚úÖ FORTALEZAS DEL DATASET:\")\nprint(\"  1. Sin valores nulos (0% missing data)\")\nprint(\"     ‚Üí No se requiere imputaci√≥n compleja\")\nprint(\"  2. Dataset de gran tama√±o (750,000 registros)\")\nprint(\"     ‚Üí Suficiente para entrenar modelos complejos y obtener resultados robustos\")\nprint(\"  3. Distribuci√≥n balanceada por g√©nero (~50/50)\")\nprint(\"     ‚Üí No hay sesgo por clase en la variable Sex\")\nprint(\"  4. Tipos de datos correctos y consistentes\")\nprint(\"     ‚Üí No se requieren conversiones complejas\")\nprint(\"  5. Rangos de valores dentro de l√≠mites fisiol√≥gicos\")\nprint(\"     ‚Üí Los datos parecen realistas y v√°lidos para modelado\")\n\n# =============================================================================\n# 2. OBSERVACIONES Y PRECAUCIONES\n# =============================================================================\nprint(\"\\n‚ö†Ô∏è OBSERVACIONES Y PRECAUCIONES:\")\n\n# Verificar si hay variables con alto porcentaje de outliers\nhigh_outliers = outliers_df[outliers_df['% Outliers'] > 5]\nif len(high_outliers) > 0:\n    print(f\"  1. Variables con alto % de outliers: {', '.join(high_outliers['Variable'].tolist())}\")\n    print(f\"     ‚Üí Evaluar si son valores v√°lidos o errores de medici√≥n\")\n    print(f\"     ‚Üí Considerar transformaciones o winsorizaci√≥n\")\nelse:\n    print(\"  1. Bajo porcentaje de outliers en todas las variables\")\n    print(\"     ‚Üí Los datos son consistentes y de buena calidad\")\n\n# Verificar variables con asimetr√≠a significativa\nskew_values = {col: train_raw[col].skew() for col in numeric_cols}\nhigh_skew = [col for col, skew in skew_values.items() if abs(skew) > 1]\nif high_skew:\n    print(f\"  2. Variables con alta asimetr√≠a: {', '.join(high_skew)}\")\n    print(f\"     ‚Üí Considerar transformaciones (log, Box-Cox, Yeo-Johnson)\")\n    print(f\"     ‚Üí Algunos modelos (√°rboles, RF) son robustos a asimetr√≠a\")\n    print(f\"     ‚Üí Modelos lineales pueden beneficiarse de normalizaci√≥n\")\n\n# =============================================================================\n# 3. CARACTER√çSTICAS GENERALES DEL DATASET\n# =============================================================================\nprint(\"\\nüìä CARACTER√çSTICAS DEL DATASET:\")\nprint(f\"  - Tama√±o total: {len(train_raw):,} registros\")\nprint(f\"  - N√∫mero de variables: {len(train_raw.columns)}\")\nprint(f\"  - Memoria utilizada: {train_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\nprint(f\"  - Variables num√©ricas: {len(numeric_cols)}\")\nprint(f\"  - Variables categ√≥ricas: 1 (Sex)\")\nprint(f\"  - Variable objetivo: Calories (regresi√≥n)\")\n\n# =============================================================================\n# 4. CONCLUSI√ìN Y RECOMENDACIONES\n# =============================================================================\nprint(\"\\n‚úÖ CONCLUSI√ìN:\")\nprint(\"  El dataset presenta EXCELENTE calidad para an√°lisis y modelado.\")\nprint(\"  No se requiere limpieza extensiva, solo preparaci√≥n est√°ndar.\")\nprint(\"\\nüìã PR√ìXIMOS PASOS RECOMENDADOS:\")\nprint(\"  1. Preparaci√≥n de datos (02_data_preparation.ipynb)\")\nprint(\"     - Codificaci√≥n de variables categ√≥ricas\")\nprint(\"     - Divisi√≥n train/validation/test\")\nprint(\"     - Normalizaci√≥n de features si es necesario\")\nprint(\"  2. An√°lisis exploratorio profundo (03_exploratory_analysis.ipynb)\")\nprint(\"     - Visualizaciones de distribuciones\")\nprint(\"     - An√°lisis de correlaciones\")\nprint(\"     - Identificaci√≥n de relaciones entre variables\")\nprint(\"  3. Feature engineering (04_feature_engineering.ipynb)\")\nprint(\"     - Creaci√≥n de features derivadas (BMI, interacciones, etc.)\")\nprint(\"     - Selecci√≥n de features m√°s relevantes\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785ec3cdb87d6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:37:17.156197Z",
     "start_time": "2025-09-14T14:37:17.050990Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# VERIFICACI√ìN DE RANGOS DE VALORES\n# =============================================================================\n# Verificar que los valores de todas las variables est√©n dentro de rangos razonables\n# Esto ayuda a detectar posibles errores de captura o valores inv√°lidos\n#\n# RANGOS FISIOL√ìGICOS ESPERADOS (Referencias):\n#   - Age: 0-120 a√±os (aunque t√≠picamente 10-100 para ejercicio)\n#   - Height: 100-250 cm (rango humano adulto: ~140-220 cm)\n#   - Weight: 20-200 kg (rango humano adulto: ~40-150 kg)\n#   - Duration: 1-180 minutos (sesiones de ejercicio t√≠picas)\n#   - Heart_Rate: 40-220 BPM (reposo: ~60-100, m√°ximo: 220-edad)\n#   - Body_Temp: 35-42¬∞C (normal: 36.5-37.5, ejercicio: hasta 40¬∞C)\n#   - Calories: 1-1000 kcal (depende de intensidad y duraci√≥n)\n\n# Verificar valores √∫nicos de la variable categ√≥rica\nprint('Sex unique:', train_raw['Sex'].unique())\nprint('  ‚Üí Solo dos valores (male/female): ‚úÖ Correcto')\n\n# Verificar rangos m√≠nimos y m√°ximos de variables num√©ricas\n# Esto permite identificar valores fuera de rangos fisiol√≥gicos esperados\nprint('\\nRangos de Variables Num√©ricas:')\nfor col in ['Age','Height','Weight','Duration','Heart_Rate','Body_Temp','Calories']:\n    if col in train_raw.columns:\n        min_val = train_raw[col].min()\n        max_val = train_raw[col].max()\n        print(f'{col:12s}: min = {min_val:7.1f}, max = {max_val:7.1f}', end='')\n        \n        # Validar rangos seg√∫n conocimiento del dominio\n        if col == 'Age' and (min_val < 10 or max_val > 100):\n            print('  ‚ö†Ô∏è Valores inusuales detectados')\n        elif col == 'Height' and (min_val < 100 or max_val > 250):\n            print('  ‚ö†Ô∏è Valores inusuales detectados')\n        elif col == 'Weight' and (min_val < 20 or max_val > 200):\n            print('  ‚ö†Ô∏è Valores inusuales detectados')\n        elif col == 'Body_Temp' and (min_val < 35 or max_val > 42):\n            print('  ‚ö†Ô∏è Valores inusuales detectados')\n        elif col == 'Heart_Rate' and (min_val < 40 or max_val > 220):\n            print('  ‚ö†Ô∏è Valores inusuales detectados')\n        else:\n            print('  ‚úÖ Rango v√°lido')\n\nprint('\\n' + '='*80)\nprint('CONCLUSI√ìN DE VERIFICACI√ìN DE RANGOS:')\nprint('  ‚úÖ Todos los valores est√°n dentro de rangos fisiol√≥gicos razonables')\nprint('  ‚úÖ No se detectaron errores evidentes en la captura de datos')\nprint('='*80)"
  },
  {
   "cell_type": "markdown",
   "id": "14d5c956954319a9",
   "metadata": {},
   "source": "## Conclusiones del An√°lisis de Data Understanding\n\n### Hallazgos Principales:\n\n1. **Calidad de Datos**: El dataset presenta **excelente calidad**:\n   - ‚úÖ 0% valores nulos (sin missing data)\n   - ‚úÖ 0 registros duplicados\n   - ‚úÖ Tipos de datos correctos y consistentes\n   - ‚úÖ Rangos de valores dentro de l√≠mites fisiol√≥gicos\n\n2. **Estructura del Dataset**:\n   - `train.csv`: 750,000 registros √ó 9 columnas (incluye variable objetivo `Calories`)\n   - `test.csv`: 250,000 registros √ó 8 columnas (sin `Calories`)\n   - **Variables num√©ricas**: Age, Height, Weight, Duration, Heart_Rate, Body_Temp, Calories\n   - **Variables categ√≥ricas**: Sex (male/female)\n\n3. **Balance del Dataset**:\n   - Distribuci√≥n de g√©nero perfectamente balanceada: 50.10% Female / 49.90% Male\n   - No se requieren t√©cnicas de balanceo de clases\n\n4. **Outliers Detectados**:\n   - Body_Temp: 1.99% outliers (14,919 registros) - Porcentaje moderado\n   - Otras variables: < 0.02% outliers - Porcentaje bajo y aceptable\n\n5. **Caracter√≠sticas de Distribuciones**:\n   - La mayor√≠a de variables tienen distribuciones **aproximadamente sim√©tricas**\n   - Body_Temp: Asimetr√≠a fuerte a la izquierda (-1.02)\n   - Calories: Asimetr√≠a moderada a la derecha (0.54)\n\n### Implicaciones para el Modelado:\n\n- ‚úÖ Dataset **listo para Machine Learning** sin necesidad de limpieza extensiva\n- ‚úÖ Gran tama√±o muestral permite entrenar modelos complejos con alta confianza\n- ‚ö° Considerar transformaciones para variables asim√©tricas (Body_Temp, Calories)\n- ‚ö° Evaluar tratamiento de outliers en Body_Temp seg√∫n contexto del problema\n\n### Pr√≥ximos Pasos:\n\n1. **02_data_preparation.ipynb**: Limpieza y preparaci√≥n de datos\n   - Codificaci√≥n de variables categ√≥ricas (One-Hot Encoding)\n   - Divisi√≥n train/validation/test\n   - Gesti√≥n de outliers si es necesario\n\n2. **03_exploratory_analysis.ipynb**: An√°lisis exploratorio profundo\n   - Visualizaciones detalladas de distribuciones\n   - An√°lisis de correlaciones entre variables\n   - Identificaci√≥n de relaciones con la variable objetivo\n\n3. **04_feature_engineering.ipynb**: Ingenier√≠a de caracter√≠sticas\n   - Creaci√≥n de features derivadas (BMI, ratios, interacciones)\n   - Normalizaci√≥n/estandarizaci√≥n de features\n   - Selecci√≥n de features m√°s relevantes\n\n---\n\n**Estado**: ‚úÖ Data Understanding completado satisfactoriamente  \n**Dataset**: Aprobado para continuar con el pipeline de Machine Learning"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}