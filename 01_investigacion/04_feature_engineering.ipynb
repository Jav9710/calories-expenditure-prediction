{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "545a6488e6da0259",
   "metadata": {},
   "source": [
    "# 04 - Feature Engineering\n",
    "\n",
    "Crear features derivados (IMC, relación peso/altura, potencia de HR sobre duración, etc.) y preparar scaler para modelado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb66707d6e99c2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:43:19.592183Z",
     "start_time": "2025-09-14T14:43:18.518472Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# CARGA DE DATOS PROCESADOS\n# =============================================================================\n# Importación de bibliotecas necesarias para feature engineering\nimport pandas as pd  # Manipulación de datos\nimport numpy as np   # Operaciones numéricas\nfrom pathlib import Path  # Manejo de rutas\nfrom sklearn.preprocessing import StandardScaler  # Normalización de features\nimport joblib  # Guardar objetos de ML (scaler)\n\n# Definir directorio de datos procesados\nDATA_DIR = Path(\"../data/processed\")\n\n# Cargar los tres conjuntos de datos preparados en el notebook anterior\ntrain = pd.read_csv(DATA_DIR / 'train.csv')  # Conjunto de entrenamiento (80%)\nval = pd.read_csv(DATA_DIR / 'val.csv')      # Conjunto de validación (20%)\ntest = pd.read_csv(DATA_DIR / 'test.csv')    # Conjunto de prueba (sin target)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b128b559f5e682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:43:41.778007Z",
     "start_time": "2025-09-14T14:43:19.844777Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# CREACIÓN DE FEATURES DERIVADAS\n# =============================================================================\n# Generar nuevas variables a partir de las existentes para mejorar el poder predictivo\n# Estas features capturan relaciones no lineales e interacciones entre variables\n\n# Aplicar la misma ingeniería de features a los tres conjuntos de datos\nfor df in (train, val, test):\n    # 1. Altura en metros (conversión de centímetros)\n    # Necesaria para cálculo correcto del BMI\n    df['Height_m'] = df['Height'] / 100.0\n    \n    # 2. BMI (Body Mass Index / Índice de Masa Corporal)\n    # Fórmula estándar: peso (kg) / altura (m)²\n    # Indicador importante de composición corporal\n    df['BMI'] = df['Weight'] / (df['Height_m']**2)\n    \n    # 3. Frecuencia cardíaca normalizada por minuto\n    # Representa la intensidad del ejercicio\n    # Evitar división por cero cuando Duration = 0\n    df['HR_per_min'] = df.apply(\n        lambda r: r['Heart_Rate'] / (r['Duration']/60.0) if r.get('Duration', 0) > 0 else 0.0, \n        axis=1\n    )\n    \n    # 4. Interacción HR × Duration\n    # Captura el efecto combinado de intensidad (HR) y duración del ejercicio\n    # Esta interacción suele ser muy predictiva del gasto calórico\n    df['HRxDuration'] = df['Heart_Rate'] * df['Duration']\n\n# Guardar versiones con feature engineering aplicado\ntrain.to_csv(DATA_DIR / 'train_fe.csv', index=False)\nval.to_csv(DATA_DIR / 'val_fe.csv', index=False)\ntest.to_csv(DATA_DIR / 'test_fe.csv', index=False)\n\nprint('Feature engineering complete and saved.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e4cac3a57bcf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:44:02.515894Z",
     "start_time": "2025-09-14T14:43:43.449285Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# NORMALIZACIÓN DE FEATURES NUMÉRICAS\n# =============================================================================\n# Estandarizar features para mejorar el rendimiento de modelos sensibles a escala\n# (regresión lineal, KNN, redes neuronales, etc.)\n\n# Definir lista de features numéricas a normalizar\nnumeric_feats = [\n    'Age',           # Edad del individuo\n    'Height',        # Altura en cm\n    'Weight',        # Peso en kg\n    'Duration',      # Duración del ejercicio (min)\n    'Heart_Rate',    # Frecuencia cardíaca (BPM)\n    'Body_Temp',     # Temperatura corporal (°C)\n    'BMI',           # Índice de masa corporal\n    'HR_per_min',    # HR normalizada por minuto\n    'HRxDuration'    # Interacción HR × Duration\n]\n\n# Crear y ajustar el scaler SOLO con datos de entrenamiento\n# Esto previene data leakage del conjunto de validación y prueba\nscaler = StandardScaler()\nscaler.fit(train[numeric_feats].fillna(0))  # Ajustar parámetros (media, std)\n\n# Aplicar transformación a todos los conjuntos y guardar versiones escaladas\nfor df, fname in [(train, 'train_fe.csv'), (val, 'val_fe.csv'), (test, 'test_fe.csv')]:\n    d = df.copy()  # Crear copia para no modificar el original\n    # Transformar features usando los parámetros aprendidos del train\n    d[numeric_feats] = scaler.transform(d[numeric_feats].fillna(0))\n    # Guardar con sufijo '_scaled' para distinguir de versión sin escalar\n    d.to_csv(DATA_DIR / fname.replace('.csv', '_scaled.csv'), index=False)\n\n# Guardar el scaler para uso en producción\n# Necesario para transformar nuevos datos de la misma manera\nPath('../results/models').mkdir(parents=True, exist_ok=True)\njoblib.dump(scaler, '../results/models/scaler.joblib')\nprint('Scaler saved to ../results/models/scaler.joblib')"
  },
  {
   "cell_type": "markdown",
   "id": "c7ac820762d6bbc0",
   "metadata": {},
   "source": [
    "Con features y scaler guardados, estamos listos para entrenar modelos base en `05_baseline_models.ipynb`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}