{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d1d30e4260a60a",
   "metadata": {},
   "source": [
    "# 02 - Data Preparation\n",
    "\n",
    "Limpieza, imputación, transformaciones iniciales y guardado de datasets listos para EDA, modelado y predicciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c9b0c67e13738",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:40:08.826940Z",
     "start_time": "2025-09-14T14:40:08.773291Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURACIÓN INICIAL Y DEFINICIÓN DE RUTAS\n# =============================================================================\n# Importación de bibliotecas necesarias para preparación de datos\nimport pandas as pd  # Manipulación de datos tabulares\nimport numpy as np   # Operaciones numéricas\nfrom pathlib import Path  # Manejo de rutas de archivos\nfrom sklearn.model_selection import train_test_split  # División de datos\nimport joblib  # Serialización de objetos para ML\n\n# Configuración de semilla aleatoria para reproducibilidad\nRANDOM_SEED = 42\n\n# Definición de directorios y rutas de archivos\nDATA_DIR = Path(\"../data\")\nTRAIN_CSV = DATA_DIR / \"raw\" / \"train.csv\"  # Dataset de entrenamiento raw\nTEST_CSV = DATA_DIR / \"raw\" / \"test.csv\"    # Dataset de prueba raw\nPROCESSED_DIR = DATA_DIR / \"processed\"      # Directorio para datos procesados\n\n# Crear directorio de datos procesados si no existe\nPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n\nprint('Processing...')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac76e0bb9e7fab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:40:14.144977Z",
     "start_time": "2025-09-14T14:40:12.740788Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# CARGA DE DATOS RAW\n# =============================================================================\n# Cargar datasets originales desde archivos CSV\ntrain = pd.read_csv(TRAIN_CSV)  # Conjunto de entrenamiento con variable objetivo\ntest = pd.read_csv(TEST_CSV)    # Conjunto de prueba sin variable objetivo\n\n# Verificar dimensiones iniciales de los datasets\nprint('Initial shapes — train:', train.shape, 'test:', test.shape)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd2d99f8419e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:40:17.614406Z",
     "start_time": "2025-09-14T14:40:17.427229Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# LIMPIEZA DE DATOS: DUPLICADOS Y TIPOS DE DATOS\n# =============================================================================\n\n# 1. Eliminación de registros duplicados basados en ID\n# Mantener solo la primera ocurrencia de cada ID único\ntrain = train.drop_duplicates(subset=['id'])\ntest = test.drop_duplicates(subset=['id'])\n\n# 2. Conversión de variable categórica a tipo 'category' para eficiencia de memoria\n# La variable 'Sex' es categórica con solo 2 valores posibles\nif 'Sex' in train.columns and train['Sex'].dtype != 'category':\n    train['Sex'] = train['Sex'].astype('category')\nif 'Sex' in test.columns and test['Sex'].dtype != 'category':\n    test['Sex'] = test['Sex'].astype('category')\n\n# 3. Asegurar tipos numéricos correctos para todas las variables numéricas\n# Convertir a numérico y manejar errores convirtiéndolos a NaN\nnumeric_cols_train = ['Age','Height','Weight','Duration','Heart_Rate','Body_Temp','Calories']\nfor c in numeric_cols_train:\n    if c in train.columns:\n        train[c] = pd.to_numeric(train[c], errors='coerce')\n\nnumeric_cols_test = ['Age','Height','Weight','Duration','Heart_Rate','Body_Temp']\nfor c in numeric_cols_test:\n    if c in test.columns:\n        test[c] = pd.to_numeric(test[c], errors='coerce')\n\n# Verificar valores nulos resultantes de la conversión\nprint('Nulos en train:\\n', train.isna().sum())\nprint('Nulos en test:\\n', test.isna().sum())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab0ef88c307207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:40:31.975328Z",
     "start_time": "2025-09-14T14:40:31.908355Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# IMPUTACIÓN DE VALORES FALTANTES\n# =============================================================================\n# Estrategia: Imputar con mediana (numéricas) o moda (categóricas) si % nulos < 20%\n# Si % nulos >= 20%, se considera un problema serio que requiere análisis adicional\n\n# Definir umbral de aceptación de valores nulos (20% del tamaño del dataset)\nthreshold = 0.2 * len(train)\n\n# Imputación en dataset de entrenamiento\nfor col in train.columns:\n    miss = train[col].isna().sum()\n    if miss > 0:\n        if miss < threshold:\n            # Imputar variables numéricas con mediana (robusto a outliers)\n            if col in numeric_cols_train:\n                train[col].fillna(train[col].median(), inplace=True)\n            else:\n                # Imputar variables categóricas con moda (valor más frecuente)\n                train[col].fillna(train[col].mode().iloc[0], inplace=True)\n        else:\n            # Advertir si hay más del 20% de valores nulos\n            print(f\"WARNING: {col} tiene {miss} nulos (>20%) en train\")\n\n# Imputación en dataset de prueba (solo para columnas existentes)\nfor col in numeric_cols_test:\n    if col in test.columns:\n        miss = test[col].isna().sum()\n        if miss > 0 and miss < threshold:\n            # Usar mediana del test set (no del train para evitar data leakage en producción)\n            test[col].fillna(test[col].median(), inplace=True)\n\n# Verificar que la imputación fue exitosa\nprint('Nulos post-imputacion (train):\\n', train.isna().sum())\nprint('Nulos post-imputacion (test):\\n', test.isna().sum())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a88003d9465e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:40:36.569959Z",
     "start_time": "2025-09-14T14:40:36.370159Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# FILTRADO DE VALORES FUERA DE RANGO\n# =============================================================================\n# Aplicar reglas de negocio para eliminar registros con valores no realistas\n# Estos rangos están basados en límites fisiológicos razonables\n\n# Filtros aplicados al conjunto de entrenamiento:\n# - Edad entre 10 y 100 años (rango humano razonable)\n# - Temperatura corporal entre 30°C y 43°C (límites de supervivencia)\n# - Duración mayor a 0 (no tiene sentido ejercicio de 0 minutos)\ntrain = train[(train['Age'] >= 10) & (train['Age'] <= 100)]\ntrain = train[(train['Body_Temp'] >= 30) & (train['Body_Temp'] <= 43)]\ntrain = train[train['Duration'] > 0]\n\n# Aplicar los mismos filtros al conjunto de prueba\n# Verificar existencia de columnas antes de filtrar (test no tiene Calories)\nif 'Age' in test.columns:\n    test = test[(test['Age'] >= 10) & (test['Age'] <= 100)]\nif 'Body_Temp' in test.columns:\n    test = test[(test['Body_Temp'] >= 30) & (test['Body_Temp'] <= 43)]\nif 'Duration' in test.columns:\n    test = test[test['Duration'] > 0]\n\n# Verificar dimensiones después del filtrado\nprint('Shapes post filter — train:', train.shape, 'test:', test.shape)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c612e846b262d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T14:40:45.887803Z",
     "start_time": "2025-09-14T14:40:40.907222Z"
    }
   },
   "outputs": [],
   "source": "# =============================================================================\n# CODIFICACIÓN DE VARIABLES CATEGÓRICAS Y DIVISIÓN DE DATOS\n# =============================================================================\n\n# 1. One-Hot Encoding de la variable 'Sex'\n# drop_first=True evita la trampa de variables dummy (multicolinealidad perfecta)\n# Mantiene solo 'Sex_male' (1 si male, 0 si female)\nif 'Sex' in train.columns:\n    train = pd.get_dummies(train, columns=['Sex'], drop_first=True)\n    # Convertir booleano a entero para compatibilidad con modelos\n    train['Sex_male'] = train['Sex_male'].astype(int)\n    \nif 'Sex' in test.columns:\n    test = pd.get_dummies(test, columns=['Sex'], drop_first=True)\n    test['Sex_male'] = test['Sex_male'].astype(int)\n\n# 2. Alinear columnas entre train y test\n# Asegurar que test tenga todas las columnas dummy creadas\nfor col in ['Sex_male']:\n    if col not in test.columns:\n        test[col] = 0  # Valor por defecto si la columna no existe\n\n# 3. División del conjunto de entrenamiento en train y validación\n# 80% entrenamiento, 20% validación\n# random_state asegura reproducibilidad de la división\ntrain_proc, val_proc = train_test_split(\n    train, \n    test_size=0.2,  # 20% para validación\n    random_state=RANDOM_SEED\n)\n\n# 4. Guardar datasets procesados para uso en notebooks posteriores\nPROCESSED_DIR = Path(\"../data/processed\")\nPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n\ntrain_proc.to_csv(PROCESSED_DIR / 'train.csv', index=False)  # Entrenamiento (80%)\nval_proc.to_csv(PROCESSED_DIR / 'val.csv', index=False)      # Validación (20%)\ntest.to_csv(PROCESSED_DIR / 'test.csv', index=False)         # Prueba (sin Calories)\n\nprint('Saved processed datasets in', PROCESSED_DIR)"
  },
  {
   "cell_type": "markdown",
   "id": "c28fa084002075b7",
   "metadata": {},
   "source": [
    "Siguiente: realizar un análisis exploratorio en `03_exploratory_analysis.ipynb` usando train y val (test se reserva para predicciones porque no tiene `Calories`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b49ce8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}